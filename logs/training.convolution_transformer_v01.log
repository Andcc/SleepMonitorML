2024-01-31 16:39:43,640 INFO GPUs found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2024-01-31 16:39:43,641 ERROR Error loading model convolution_transformer_v01: No file or directory found at ../models/convolution_transformer_v01
2024-01-31 16:41:38,410 INFO GPUs found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2024-01-31 16:41:38,462 ERROR Error loading model convolution_transformer_v01: No file or directory found at ../models/convolution_transformer_v01
2024-01-31 16:43:21,608 INFO GPUs found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2024-01-31 16:43:22,235 INFO Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 150, 2)]             0         []                            
                                                                                                  
 conv1d (Conv1D)             (None, 150, 32)              224       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 150, 32)              128       ['conv1d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 dropout (Dropout)           (None, 150, 32)              0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv1d_1 (Conv1D)           (None, 150, 64)              6208      ['dropout[0][0]']             
                                                                                                  
 batch_normalization_1 (Bat  (None, 150, 64)              256       ['conv1d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 dropout_1 (Dropout)         (None, 150, 64)              0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 conv1d_2 (Conv1D)           (None, 150, 128)             24704     ['dropout_1[0][0]']           
                                                                                                  
 batch_normalization_2 (Bat  (None, 150, 128)             512       ['conv1d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 dropout_2 (Dropout)         (None, 150, 128)             0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 position_embedding (keras_  (None, 150, 128)             19200     ['dropout_2[0][0]']           
 nlp>PositionEmbedding)                                                                           
                                                                                                  
 tf.__operators__.add (TFOp  (None, 150, 128)             0         ['dropout_2[0][0]',           
 Lambda)                                                             'position_embedding[0][0]']  
                                                                                                  
 transformer_block (Transfo  (None, 150, 128)             330240    ['tf.__operators__.add[0][0]']
 rmerBlock)                                                                                       
                                                                                                  
 transformer_block_1 (Trans  (None, 150, 128)             330240    ['transformer_block[0][0]']   
 formerBlock)                                                                                     
                                                                                                  
 time_distributed (TimeDist  (None, 150, 3)               387       ['transformer_block_1[0][0]'] 
 ributed)                                                                                         
                                                                                                  
==================================================================================================
Total params: 712099 (2.72 MB)
Trainable params: 711651 (2.71 MB)
Non-trainable params: 448 (1.75 KB)
__________________________________________________________________________________________________
2024-01-31 16:43:30,501 WARNING Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0760s vs `on_train_batch_end` time: 0.0904s). Check your callbacks.
2024-01-31 16:52:12,994 INFO GPUs found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2024-01-31 16:52:13,590 INFO Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 150, 2)]             0         []                            
                                                                                                  
 conv1d (Conv1D)             (None, 150, 32)              224       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 150, 32)              128       ['conv1d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 dropout (Dropout)           (None, 150, 32)              0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv1d_1 (Conv1D)           (None, 150, 64)              6208      ['dropout[0][0]']             
                                                                                                  
 batch_normalization_1 (Bat  (None, 150, 64)              256       ['conv1d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 dropout_1 (Dropout)         (None, 150, 64)              0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 conv1d_2 (Conv1D)           (None, 150, 128)             24704     ['dropout_1[0][0]']           
                                                                                                  
 batch_normalization_2 (Bat  (None, 150, 128)             512       ['conv1d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 dropout_2 (Dropout)         (None, 150, 128)             0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 position_embedding (keras_  (None, 150, 128)             19200     ['dropout_2[0][0]']           
 nlp>PositionEmbedding)                                                                           
                                                                                                  
 tf.__operators__.add (TFOp  (None, 150, 128)             0         ['dropout_2[0][0]',           
 Lambda)                                                             'position_embedding[0][0]']  
                                                                                                  
 transformer_block (Transfo  (None, 150, 128)             330240    ['tf.__operators__.add[0][0]']
 rmerBlock)                                                                                       
                                                                                                  
 transformer_block_1 (Trans  (None, 150, 128)             330240    ['transformer_block[0][0]']   
 formerBlock)                                                                                     
                                                                                                  
 time_distributed (TimeDist  (None, 150, 3)               387       ['transformer_block_1[0][0]'] 
 ributed)                                                                                         
                                                                                                  
==================================================================================================
Total params: 712099 (2.72 MB)
Trainable params: 711651 (2.71 MB)
Non-trainable params: 448 (1.75 KB)
__________________________________________________________________________________________________
2024-01-31 16:52:22,066 WARNING Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1348s vs `on_train_batch_end` time: 0.1803s). Check your callbacks.
2024-01-31 17:07:52,951 INFO Epoch 1: Loss: 0.10439397394657135, Custom AUC: 0.5032356381416321
2024-01-31 17:21:53,380 INFO Epoch 2: Loss: 0.04688207805156708, Custom AUC: 0.5056580305099487
2024-01-31 17:21:54,598 INFO Training finished. Loss: 0.04688207805156708, Custom AUC: 0.5056580305099487
2024-01-31 17:21:54,598 INFO Model trained
2024-01-31 17:21:54,922 INFO Unsupported signature for serialization: ((TensorSpec(shape=(150, 128), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f584c1675b0>, 140019081592240), {}).
2024-01-31 17:21:55,281 INFO Unsupported signature for serialization: ((TensorSpec(shape=(150, 128), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f584c1675b0>, 140019081592240), {}).
2024-01-31 17:21:56,024 INFO Assets written to: ../models/convolution_transformer_v01/assets
2024-01-31 17:21:56,081 INFO Model Saved.
Done.
2024-01-31 17:48:25,497 INFO GPUs found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2024-01-31 17:48:26,281 INFO Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 150, 2)]             0         []                            
                                                                                                  
 conv1d (Conv1D)             (None, 150, 32)              224       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 150, 32)              128       ['conv1d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 dropout (Dropout)           (None, 150, 32)              0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv1d_1 (Conv1D)           (None, 150, 64)              6208      ['dropout[0][0]']             
                                                                                                  
 batch_normalization_1 (Bat  (None, 150, 64)              256       ['conv1d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 dropout_1 (Dropout)         (None, 150, 64)              0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 conv1d_2 (Conv1D)           (None, 150, 128)             24704     ['dropout_1[0][0]']           
                                                                                                  
 batch_normalization_2 (Bat  (None, 150, 128)             512       ['conv1d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 dropout_2 (Dropout)         (None, 150, 128)             0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 position_embedding (keras_  (None, 150, 128)             19200     ['dropout_2[0][0]']           
 nlp>PositionEmbedding)                                                                           
                                                                                                  
 tf.__operators__.add (TFOp  (None, 150, 128)             0         ['dropout_2[0][0]',           
 Lambda)                                                             'position_embedding[0][0]']  
                                                                                                  
 transformer_block (Transfo  (None, 150, 128)             330240    ['tf.__operators__.add[0][0]']
 rmerBlock)                                                                                       
                                                                                                  
 transformer_block_1 (Trans  (None, 150, 128)             330240    ['transformer_block[0][0]']   
 formerBlock)                                                                                     
                                                                                                  
 time_distributed (TimeDist  (None, 150, 3)               387       ['transformer_block_1[0][0]'] 
 ributed)                                                                                         
                                                                                                  
==================================================================================================
Total params: 712099 (2.72 MB)
Trainable params: 711651 (2.71 MB)
Non-trainable params: 448 (1.75 KB)
__________________________________________________________________________________________________
2024-01-31 17:48:34,859 WARNING Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1338s vs `on_train_batch_end` time: 0.1772s). Check your callbacks.
2024-01-31 18:04:21,941 INFO Epoch 1: Loss: 0.04526663199067116, Custom AUC: 0.5225254893302917
2024-01-31 18:17:49,762 INFO Epoch 2: Loss: 0.04464787244796753, Custom AUC: 0.5268150568008423
2024-01-31 18:17:50,982 INFO Training finished. Loss: 0.04464787244796753, Custom AUC: 0.5268150568008423
2024-01-31 18:17:50,982 INFO Model trained
2024-01-31 18:17:51,358 INFO Unsupported signature for serialization: ((TensorSpec(shape=(150, 128), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f109833bb80>, 139710925561552), {}).
2024-01-31 18:17:51,619 INFO Unsupported signature for serialization: ((TensorSpec(shape=(150, 128), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f109833bb80>, 139710925561552), {}).
2024-01-31 18:17:52,308 INFO Assets written to: ../models/convolution_transformer_v01/assets
2024-01-31 18:17:52,363 INFO Model Saved.
Done.
2024-01-31 18:54:35,354 INFO GPUs found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2024-01-31 18:54:37,170 INFO Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 150, 2)]             0         []                            
                                                                                                  
 conv1d (Conv1D)             (None, 150, 32)              224       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 150, 32)              128       ['conv1d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 dropout (Dropout)           (None, 150, 32)              0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv1d_1 (Conv1D)           (None, 150, 64)              6208      ['dropout[0][0]']             
                                                                                                  
 batch_normalization_1 (Bat  (None, 150, 64)              256       ['conv1d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 dropout_1 (Dropout)         (None, 150, 64)              0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 conv1d_2 (Conv1D)           (None, 150, 128)             24704     ['dropout_1[0][0]']           
                                                                                                  
 batch_normalization_2 (Bat  (None, 150, 128)             512       ['conv1d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 dropout_2 (Dropout)         (None, 150, 128)             0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 position_embedding (keras_  (None, 150, 128)             19200     ['dropout_2[0][0]']           
 nlp>PositionEmbedding)                                                                           
                                                                                                  
 tf.__operators__.add (TFOp  (None, 150, 128)             0         ['dropout_2[0][0]',           
 Lambda)                                                             'position_embedding[0][0]']  
                                                                                                  
 transformer_block (Transfo  (None, 150, 128)             330240    ['tf.__operators__.add[0][0]']
 rmerBlock)                                                                                       
                                                                                                  
 transformer_block_1 (Trans  (None, 150, 128)             330240    ['transformer_block[0][0]']   
 formerBlock)                                                                                     
                                                                                                  
 time_distributed (TimeDist  (None, 150, 3)               387       ['transformer_block_1[0][0]'] 
 ributed)                                                                                         
                                                                                                  
==================================================================================================
Total params: 712099 (2.72 MB)
Trainable params: 711651 (2.71 MB)
Non-trainable params: 448 (1.75 KB)
__________________________________________________________________________________________________
2024-01-31 18:54:45,441 WARNING Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1335s vs `on_train_batch_end` time: 0.1773s). Check your callbacks.
2024-01-31 19:08:07,128 INFO Epoch 1: Loss: 0.04435426741838455, Custom AUC: 0.5417085289955139
2024-01-31 19:21:27,567 INFO Epoch 2: Loss: 0.04416386038064957, Custom AUC: 0.5452380180358887
2024-01-31 19:34:42,232 INFO Epoch 3: Loss: 0.04399874806404114, Custom AUC: 0.5485835671424866
2024-01-31 19:47:57,980 INFO Epoch 4: Loss: 0.043857742100954056, Custom AUC: 0.5528337359428406
2024-01-31 20:01:11,526 INFO Epoch 5: Loss: 0.04368944466114044, Custom AUC: 0.5570504069328308
2024-01-31 20:15:04,360 INFO Epoch 6: Loss: 0.04352359473705292, Custom AUC: 0.5614374876022339
2024-01-31 20:28:49,568 INFO Epoch 7: Loss: 0.043262917548418045, Custom AUC: 0.5663057565689087
2024-01-31 20:42:18,001 INFO Epoch 8: Loss: 0.04293466731905937, Custom AUC: 0.5719773769378662
2024-01-31 20:55:32,317 INFO Epoch 9: Loss: 0.04258519411087036, Custom AUC: 0.5784338712692261
2024-01-31 21:08:50,600 INFO Epoch 10: Loss: 0.04227374121546745, Custom AUC: 0.5852372646331787
2024-01-31 21:08:51,807 INFO Training finished. Loss: 0.04227374121546745, Custom AUC: 0.5852372646331787
2024-01-31 21:08:51,808 INFO Model trained
2024-01-31 21:08:52,188 INFO Unsupported signature for serialization: ((TensorSpec(shape=(150, 128), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7ff0904baaf0>, 140672461626896), {}).
2024-01-31 21:08:52,443 INFO Unsupported signature for serialization: ((TensorSpec(shape=(150, 128), dtype=tf.float32, name='gradient'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7ff0904baaf0>, 140672461626896), {}).
2024-01-31 21:08:53,139 INFO Assets written to: ../models/convolution_transformer_v01/assets
2024-01-31 21:08:53,195 INFO Model Saved.
Done.
2024-01-31 22:47:36,525 INFO GPUs found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2024-01-31 22:47:37,306 INFO Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 input_1 (InputLayer)        [(None, 150, 2)]             0         []                            
                                                                                                  
 conv1d (Conv1D)             (None, 150, 32)              224       ['input_1[0][0]']             
                                                                                                  
 batch_normalization (Batch  (None, 150, 32)              128       ['conv1d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 dropout (Dropout)           (None, 150, 32)              0         ['batch_normalization[0][0]'] 
                                                                                                  
 conv1d_1 (Conv1D)           (None, 150, 64)              6208      ['dropout[0][0]']             
                                                                                                  
 batch_normalization_1 (Bat  (None, 150, 64)              256       ['conv1d_1[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 dropout_1 (Dropout)         (None, 150, 64)              0         ['batch_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 conv1d_2 (Conv1D)           (None, 150, 128)             24704     ['dropout_1[0][0]']           
                                                                                                  
 batch_normalization_2 (Bat  (None, 150, 128)             512       ['conv1d_2[0][0]']            
 chNormalization)                                                                                 
                                                                                                  
 dropout_2 (Dropout)         (None, 150, 128)             0         ['batch_normalization_2[0][0]'
                                                                    ]                             
                                                                                                  
 position_embedding (keras_  (None, 150, 128)             19200     ['dropout_2[0][0]']           
 nlp>PositionEmbedding)                                                                           
                                                                                                  
 tf.__operators__.add (TFOp  (None, 150, 128)             0         ['dropout_2[0][0]',           
 Lambda)                                                             'position_embedding[0][0]']  
                                                                                                  
 transformer_block (Transfo  (None, 150, 128)             330240    ['tf.__operators__.add[0][0]']
 rmerBlock)                                                                                       
                                                                                                  
 transformer_block_1 (Trans  (None, 150, 128)             330240    ['transformer_block[0][0]']   
 formerBlock)                                                                                     
                                                                                                  
 time_distributed (TimeDist  (None, 150, 3)               387       ['transformer_block_1[0][0]'] 
 ributed)                                                                                         
                                                                                                  
==================================================================================================
Total params: 712099 (2.72 MB)
Trainable params: 711651 (2.71 MB)
Non-trainable params: 448 (1.75 KB)
__________________________________________________________________________________________________
2024-01-31 22:47:45,674 WARNING Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1344s vs `on_train_batch_end` time: 0.1783s). Check your callbacks.
2024-01-31 23:01:00,672 INFO Epoch 1: Loss: 0.041971296072006226, Custom AUC: 0.6621177792549133
2024-01-31 23:14:19,110 INFO Epoch 2: Loss: 0.04170919954776764, Custom AUC: 0.6665899157524109
2024-01-31 23:27:31,757 INFO Epoch 3: Loss: 0.04145175591111183, Custom AUC: 0.6725124716758728
2024-01-31 23:40:44,606 INFO Epoch 4: Loss: 0.04119321331381798, Custom AUC: 0.6789626479148865
2024-01-31 23:53:57,317 INFO Epoch 5: Loss: 0.04092516377568245, Custom AUC: 0.6850296258926392
2024-02-01 00:07:10,095 INFO Epoch 6: Loss: 0.04069848358631134, Custom AUC: 0.6904224157333374
2024-02-01 00:20:22,947 INFO Epoch 7: Loss: 0.040468230843544006, Custom AUC: 0.6955974102020264
2024-02-01 00:33:35,746 INFO Epoch 8: Loss: 0.04030303657054901, Custom AUC: 0.7004188895225525
2024-02-01 00:46:48,450 INFO Epoch 9: Loss: 0.04015769809484482, Custom AUC: 0.7046861052513123
2024-02-01 01:00:01,261 INFO Epoch 10: Loss: 0.03998686745762825, Custom AUC: 0.7085986733436584
2024-02-01 01:13:13,923 INFO Epoch 11: Loss: 0.03982294350862503, Custom AUC: 0.7123867869377136
2024-02-01 01:26:26,696 INFO Epoch 12: Loss: 0.03969116881489754, Custom AUC: 0.7158353924751282
2024-02-01 01:39:39,411 INFO Epoch 13: Loss: 0.039593420922756195, Custom AUC: 0.7190733551979065
2024-02-01 01:52:52,170 INFO Epoch 14: Loss: 0.039436910301446915, Custom AUC: 0.7221065163612366
2024-02-01 02:06:05,032 INFO Epoch 15: Loss: 0.03933209553360939, Custom AUC: 0.7249770164489746
2024-02-01 02:19:17,839 INFO Epoch 16: Loss: 0.039203450083732605, Custom AUC: 0.727715253829956
2024-02-01 02:32:30,671 INFO Epoch 17: Loss: 0.03914615139365196, Custom AUC: 0.730316162109375
2024-02-01 02:45:43,510 INFO Epoch 18: Loss: 0.039024900645017624, Custom AUC: 0.7327456474304199
2024-02-01 02:58:56,374 INFO Epoch 19: Loss: 0.03891536965966225, Custom AUC: 0.7350308895111084
2024-02-01 03:12:09,208 INFO Epoch 20: Loss: 0.038811106234788895, Custom AUC: 0.7373117804527283
2024-02-01 03:25:22,101 INFO Epoch 21: Loss: 0.038727082312107086, Custom AUC: 0.7394831776618958
2024-02-01 03:38:34,821 INFO Epoch 22: Loss: 0.0386589951813221, Custom AUC: 0.7415467500686646
2024-02-01 03:51:47,644 INFO Epoch 23: Loss: 0.03857040777802467, Custom AUC: 0.7435163855552673
2024-02-01 04:05:00,518 INFO Epoch 24: Loss: 0.03849297761917114, Custom AUC: 0.7454233169555664
2024-02-01 04:18:13,494 INFO Epoch 25: Loss: 0.03841812163591385, Custom AUC: 0.7472450733184814
2024-02-01 04:31:26,285 INFO Epoch 26: Loss: 0.038330089300870895, Custom AUC: 0.749045193195343
2024-02-01 04:44:39,030 INFO Epoch 27: Loss: 0.03822396323084831, Custom AUC: 0.7507562041282654
2024-02-01 04:57:51,848 INFO Epoch 28: Loss: 0.03818706423044205, Custom AUC: 0.7523822784423828
2024-02-01 05:11:04,682 INFO Epoch 29: Loss: 0.038103342056274414, Custom AUC: 0.7540002465248108
2024-02-01 05:24:17,464 INFO Epoch 30: Loss: 0.03803024813532829, Custom AUC: 0.755551278591156
2024-02-01 05:37:30,411 INFO Epoch 31: Loss: 0.03796261548995972, Custom AUC: 0.7570628523826599
2024-02-01 05:50:43,015 INFO Epoch 32: Loss: 0.037895362824201584, Custom AUC: 0.7585150599479675
2024-02-01 06:03:55,766 INFO Epoch 33: Loss: 0.03782395273447037, Custom AUC: 0.7599639296531677
2024-02-01 06:17:08,630 INFO Epoch 34: Loss: 0.037773631513118744, Custom AUC: 0.7613510489463806
2024-02-01 06:30:21,175 INFO Epoch 35: Loss: 0.037747908383607864, Custom AUC: 0.7626855373382568
2024-02-01 06:43:37,759 INFO Epoch 36: Loss: 0.03765375167131424, Custom AUC: 0.7639822363853455
2024-02-01 06:57:00,161 INFO Epoch 37: Loss: 0.03760318458080292, Custom AUC: 0.7652573585510254
2024-02-01 07:10:14,039 INFO Epoch 38: Loss: 0.03754693269729614, Custom AUC: 0.7664598822593689
2024-02-01 07:23:27,089 INFO Epoch 39: Loss: 0.03749214857816696, Custom AUC: 0.7676804065704346
2024-02-01 07:36:44,581 INFO Epoch 40: Loss: 0.03745758533477783, Custom AUC: 0.768872857093811
2024-02-01 07:50:04,721 INFO Epoch 41: Loss: 0.03737683966755867, Custom AUC: 0.7699686288833618
2024-02-01 08:03:25,190 INFO Epoch 42: Loss: 0.037298426032066345, Custom AUC: 0.7711097598075867
2024-02-01 08:16:43,594 INFO Epoch 43: Loss: 0.03725152462720871, Custom AUC: 0.7722113728523254
2024-02-01 08:29:58,590 INFO Epoch 44: Loss: 0.03719271346926689, Custom AUC: 0.7732852697372437
2024-02-01 08:43:13,189 INFO Epoch 45: Loss: 0.03718553110957146, Custom AUC: 0.7742969393730164
2024-02-01 08:56:27,453 INFO Epoch 46: Loss: 0.03714221715927124, Custom AUC: 0.7753186225891113
2024-02-01 09:09:45,331 INFO Epoch 47: Loss: 0.0370483472943306, Custom AUC: 0.7763152122497559
2024-02-01 09:23:00,563 INFO Epoch 48: Loss: 0.036995939910411835, Custom AUC: 0.7773141860961914
2024-02-01 09:36:13,754 INFO Epoch 49: Loss: 0.03692871704697609, Custom AUC: 0.7782754898071289
2024-02-01 09:49:32,861 INFO Epoch 50: Loss: 0.036869823932647705, Custom AUC: 0.7792165279388428
2024-02-01 10:02:53,577 INFO Epoch 51: Loss: 0.03686121106147766, Custom AUC: 0.7801510095596313
2024-02-01 10:16:07,271 INFO Epoch 52: Loss: 0.036797381937503815, Custom AUC: 0.7810431122779846
2024-02-01 10:29:20,953 INFO Epoch 53: Loss: 0.03673660010099411, Custom AUC: 0.7819343209266663
